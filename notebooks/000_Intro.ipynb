{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**[Oreum Industries](https://oreum.io/) Reference Project, 2024Q3**\n",
        "\n",
        "---\n",
        "\n",
        "# 000_Intro.ipynb\n",
        "\n",
        "### Oreum Reference - Copula Regression `oreum_copula`\n",
        "\n",
        "Demonstrate Bayesian Copula Regression Modelling using Bayesian inference and a Bayesian workflow, specifically using \n",
        "the `pymc` & `arviz` ecosystem.\n",
        "\n",
        "This **Intro** can also be used for verbal presentation and discussion purposes, ideally followed by a deeper technical \n",
        "walkthrough of the project in a long-form style. Because this project is a reference, it contains huge amounts of detail \n",
        "which is not worthwhile to summarise too much. \n",
        "\n",
        "The interested reader should refer to the project notebooks where we evaluate the behaviour and performance of the \n",
        "models throughout the workflows, including several state-of-the-art methods unavailable to conventional max-likelihood \n",
        "/ machine-learning models.\n",
        "\n",
        "[PDF version](000_Intro.pdf)\n",
        "\n",
        "[Oreum Industries: Technical Resources](https://github.com/oreum-industries)\n",
        "\n",
        "<a href='https://oreum.io'><img src='../assets/img/Oreum_wordmark_black_right_aligned_S.png' width='300px' style=\"float: right;\"/></a><div style=\"clear:both\"/>\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## _What is Copula Regression?_\n",
        "\n",
        "We seek to create _principled_ models that provide explanatory inference and predictions of Marginal distributions $M$\n",
        "that are jointly coupled by a Latent Copula $C$, using quantified uncertainty to support real-world decision-making.\n",
        "\n",
        "<img src='../plots/000_jointplot_corr.png' width='480px'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "**Motivation:**\n",
        "\n",
        "+ A classic use-case for this model architecture (in the 2-dimensional setting) is insurance claims frequency and severity\n",
        "+ The `frequency` of claims and the `severity` of each claim each have marginal distributions and a natural covariance \n",
        "  $\\Sigma$ between marginals $M_{0}, M_{1}$\n",
        "+ The joint product `frequency * severity = Loss Cost` i.e. the dollar value of insurable losses\n",
        "+ If we use a naive model that doesn't account for the covariance between `frequency` and `severity`, then the model \n",
        "  predictions for `Loss Cost` can be hugely wrong!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "<img src='../plots/000_jointplot_corr.png' width='360px'/>\n",
        "\n",
        "\n",
        "**Demonstration:**\n",
        "\n",
        "+ In this notebook:\n",
        "  + We create a small synthetic dataset of observations of two marginals $M_{0}, M_{1}$ which have \n",
        "    covariance $\\Sigma$, and also (because we can) a version of the marginals $M_{0x}, M_{1x}$ without covariance\n",
        "  + We compare the resulting values of the joint product $y = M_{0} * M_{1}$ vs $y = M_{0x} * M_{1x}$ and see that impact\n",
        "    of ignoring the covariance is substantial.\n",
        "+ In the rest of the reference guide:\n",
        "  + We create a series of principled copula models using advanced architectures and Bayesian inference to fit to the \n",
        "    data and estimate the covariance on $M_{0}, M_{1}$\n",
        "  + The first model is naive and ignores the covariance, the final model is very sophisticated and estimates the covariance\n",
        "  + We demonstrate **a substantial 32 percentage-point improvement in model accuracy** when using a copula-based model\n",
        "  + This correct estimation would likely make the difference between profitable pricing / accurate reserving, or greatly loss-making business over a portfolio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "**General project approach**\n",
        "\n",
        "The emphasis in this project is to build a variety of models of increasing sophistication and demonstrate their usage. \n",
        "We strike a balance between building up concepts & methods vs practical application & worked examples in a `pymc`-based \n",
        "Bayesian workflow.\n",
        "\n",
        "We don't focus on specific analysis of the dataset, nor try to infer too much. The dataset is simply a good substrate on\n",
        "which to learn and demonstrate the variety of model architectures used herein.\n",
        "\n",
        "We evaluate the behaviour and performance of the models throughout the workflows, including several state-of-the-art \n",
        "methods unavailable to conventional max-likelihood / machine-learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "**This series of Notebooks covers**\n",
        "\n",
        "+ `000_Intro.ipynb`: Orientiation and fundamental concepts \n",
        "+ `100_ModelA0.ipynb`: Core (naive) architecture: Create priors, marginal likelihoods, but no copula\n",
        "+ `101_ModelA1.ipynb`: Partial architecture (extends ModelA0): Include Gaussian copula (w/ Jacobian adjustment), and several technical innovations to let `pymc` work with the transformations\n",
        "+ `102_ModelA2.ipynb`: Full architecture (extends ModelA1): Include Jacobian Adjustment on transformed observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "**In this Notebook**\n",
        "\n",
        "We dive straight into **Orientation** and **Fundamental General Abstractions** with a simple real-world \n",
        "observational censored dataset, and then go on to demonstrate the theory and usage of an increasing sophistication of models.\n",
        "\n",
        "\n",
        "## Contents\n",
        "\n",
        "+ [Setup](#Setup)\n",
        "\n",
        "+ [Preamble: Why Bayes?](#Preamble:-Why-Bayes?)\n",
        "\n",
        "+ [1. Orientation: Copula Functions and Their Behaviour](#1.-Orientation:-Copula-Functions-and-Their-Behaviour)\n",
        "\n",
        "+ [2. Brief Technical Summary: The Copula Model designed in this Project](#2.-Brief-Technical-Summary:-The-Copula-Model-designed-in-this-Project)\n",
        "\n",
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jon/workspace/oreum/oreum_core/oreum_core/eda/plot.py:915: SyntaxWarning: invalid escape sequence '\\m'\n",
            "  f\"$\\mu = {mn:,.{j}f}$, \"  # for {yhat_nm}\n",
            "/Users/jon/workspace/oreum/oreum_core/oreum_core/eda/plot.py:948: SyntaxWarning: invalid escape sequence '\\g'\n",
            "  f\"$P_{{@{{{q:.2f}}}}} \\geq {{{qv:.{j}f}}}$\"\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from oreum_core import eda\n",
        "from pyprojroot.here import here\n",
        "\n",
        "# prepend local project src files\n",
        "module_path = here('src').resolve(strict=True)\n",
        "if str(module_path) not in sys.path:\n",
        "    sys.path.insert(0, str(module_path))\n",
        "\n",
        "from engine import logger\n",
        "from synthetic.create_copula import CopulaBuilder\n",
        "\n",
        "# autoreload local modules to allow local dev\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import warnings  # noqa\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)  # noqa\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)  # noqa\n",
        "import seaborn as sns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "source": [
        "### Notebook config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "log = logger.get_logger('000_Intro', notebook=True)\n",
        "_ = logger.get_logger('oreum_core', notebook=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "source": [
        "### Local Functions and Global Vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "RSD = 42\n",
        "RNG = np.random.default_rng(seed=RSD)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "source": [
        "### Data Connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "figio = eda.FigureIO(here(Path('plots')).resolve(strict=True))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# Preamble: Why Bayes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## We gain massive advantage by using a Bayesian Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We specifically use [**Bayesian Inference**](https://betanalpha.github.io/assets/case_studies/modeling_and_inference.html)\n",
        "rather than Frequentist Max-Likelihood methods for many reasons, including:\n",
        "\n",
        "|  | Bayesian Inference | Frequentist Max-Likelihood   | \n",
        "| --- | --- | ---|\n",
        "| **General formulation** $\\rightarrow$<br/> **Desirable Trait** $\\downarrow$ | _Bayes' Rule_ $$\\underbrace{P(\\hat{\\mathcal{H}}\\|D)}_{\\text{posterior}} = \\frac{\\overbrace{P(D\\|\\mathcal{H})}^{\\text{likelihood}} \\cdot \\overbrace{P(\\mathcal{H})}^{\\text{prior}}}{\\underbrace{P(D)}_{\\text{evidence}}} $$ | _MLE_ $$\\hat{\\mathcal{H}}^{\\text{MLE}} \\propto \\arg\\max_{\\mathcal{H}} P(D\\|\\mathcal{H})$$ |\n",
        "| **_Principled_ model structure represents hypothesis about the data-generating process** | **Very strong** <br/> Can build bespoke arbitrary and hierarchical structures of parameters to map to the real-world data-generating process. | **Weak** <br/> Can only state structure under strict limited assumptions of model statistical validity. |\n",
        "| **Model parameters and their initial values represent domain expert knowledge** | **Very strong** <br/>Marginal prior distributions represent real-world probability of parameter values before any data is seen. | **Very weak** <br/> No concept of priors. Lack of joint probability distribution can lead to discontinuities in parameter values. |\n",
        "| **Robust parameter fitting process** | **Strong** <br/> Estimate full joint posterior probability mass distribution for parameters - more stable and representative of the expectation for the parameter values. Sampling can be a computationally expensive process. | **Weak** <br/> Estimate single-point max-aposterioi-likelihood (density) of  parameters - this can be far outside the probability mass and so is prone to overfitting and only correct in the limit of infinite data. But optimization method can be computationally cheap. |\n",
        "| **Fitted parameters have meaningful summary statistics for inference** | **Very strong** <br/>Full marginal probability distributions can be interpreted exactly as probabilities. | **Weak** <br/>Point estimates only have meaningful summary statistics under strict limited assumptions of model statistical validity. |\n",
        "\n",
        "\n",
        "continues ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "... continued\n",
        "\n",
        "| Desirable Trait | Bayesian Inference | Frequentist Max-Likelihood |\n",
        "| --- | --- | ---|\n",
        "| **Robust model evaluation process** | **Strong** <br/>Use entire dataset, evaluate via Leave-One-Out Cross Validation (best theoretically possible). | **Weak** <br/> Cross-validation rarely seen in practice, even if used, rarely better than 5-fold CV. Simplistic method can be computationally cheap. |\n",
        "| **Predictions made with quantified variance** | **Very strong** <br/>Predictions made using full posterior probability distributions, so predictions have full empirical probability distributions. | **Weak** <br/>Predictions using point estimates can be bootstrapped, but predictions only have interpretation under strict limited assumptions of model validity. |\n",
        "| **Handle imbalanced, high cardinality & hierarchical factor features** | **Very strong** <br/>Can introduce partial-pooling to automatically balance factors through hierarchical priors. | **Weak** <br/>Difficult to introduce partial-pooling (aka mixed random effects) without affecting strict limited assumptions of model validity. |\n",
        "| **Handle skewed / multimodal / extreme value target variable** | **Very strong** <br/>Represent the model likelihood as any arbitrary probability distribution, including mixture (compound) functions e.g. a zero-inflated Weibull. | **Weak** <br/>Represent model likelihood with a usually very limited set of distributions. Very difficult to create mixture compound functions. |\n",
        "| **Handle small datasets** | **Very strong** <br/>Bayesian concept assumes that there is a probable range of values for each parameter, and that we evidence our prior on any amount of data (even very small counts). | **Very weak** <br/>Frequentist concept assumes that there is a single true value for each parameter and that we only discover that value in the limit (of infinite observations). |\n",
        "| **Automatically impute missing data** | **Very strong** <br/>Establish a prior for each datapoint, evidence on the available data within the context of the model, to automatically impute missing values. | **Very weak** <br/>No inherent method. Usually impute as a pre-processing step with weak non-modelled methods. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## Practical Implementations of Bayesian Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "We briefly referenced _Bayes Rule_ above, which is a useful mnemonic when discussing Bayesian Inference, but in practice\n",
        "the crux of putting these advanced statistical techniques into practice is estimating the evidence $P(D)$ i.e. the \n",
        "probability of observing the data that we use to evidence the model\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\underbrace{P(\\hat{\\mathcal{H}}|D)}_{\\text{posterior}} &= \n",
        "    \\frac{\\overbrace{P(D|\\mathcal{H})}^{\\text{likelihood}} \\cdot \n",
        "    \\overbrace{P(\\mathcal{H})}^{\\text{prior}}}{\\underbrace{P(D)}_{\\text{evidence}}} \\\\\n",
        "\\\\\n",
        "\\text{...where:} \\\\\n",
        "\\\\\n",
        "P(D) &\\sim \\int_{\\Theta} P(D, \\theta)\\ d\\theta \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This joint probability $P(D, \\theta)$ of data $D$ and parameters $\\theta$ requires an almost impossible-to-solve integral\n",
        "over parameter-space $\\Theta$. Rather than attempt to calculate that integral, we do something that sounds far more \n",
        "difficult, but given modern computing capabilities is actually practical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "### We use a Bleeding-edge MCMC Toolkit for Bayesian Inference: `pymc` & `arviz`\n",
        "\n",
        "We use **Markov Chain Monte-Carlo (MCMC)** sampling to take a series of _ergodic_, _partly-reversible_, _partly-randomised_ \n",
        "samples of model parameters $\\theta$, and at each step compute the ratio of log-likelihoods $\\log P(D|\\mathcal{H})$ \n",
        "between a starting position (current values) $\\theta_{p0}$ and proposed \"sampled\" position $\\theta_{p}$ in parameter \n",
        "space, so as to reduce that log-likelihood (whilst exploring the parameter space). \n",
        "\n",
        "This results in a posterior estimate $P(\\hat{\\theta}|D)$:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "P(\\hat{\\theta}|D) &\\sim \n",
        "    \\frac{\\overbrace{P(D|\\theta_{p})}^{\\text{likelihood @ proposal}} \\cdot \\overbrace{P(\\theta_{p})}^{\\text{prior @ proposal}}}\n",
        "    {\\underbrace{P(D|\\theta_{p0})}_{\\text{likelihood @ current}} \\cdot \\underbrace{P(\\theta_{p0})}_{\\text{prior @ current}}}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This is the heart of MCMC sampling: for detailed practical explanations see [Betancourt, 2021](https://betanalpha.github.io/assets/case_studies/sampling.html), [Carroll, 2019](https://colindcarroll.com/2019/04/11/hamiltonian-monte-carlo-from-scratch/), and [Tweicki, 2015](https://twiecki.io/blog/2015/11/10/mcmc-sampling/)\n",
        "\n",
        "We use the bleeding-edge [`pymc`](https://www.pymc.io/welcome.html) and [`arviz`](https://python.arviz.org/en/stable/)\n",
        "Python packages to provide the full Bayesian toolkit that we require, including advanced sampling, probabilistic programming, \n",
        "statistical inferences, model evaluation and comparison, and more.\n",
        "\n",
        "<img src='../assets/img/logos.png' width='600px'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# 1. Orientation: Copula Functions and Their Behaviour"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## 1.1 Create Synthetic Copula Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "We can learn a lot by creating a synthetic copula dataset using a \"forward-pass\":\n",
        "\n",
        "1. Start with random data $C$ sampled from the PDF of a Latent Copula function $\\square_{\\mathfrak{C}}$ with 2-dimensions\n",
        "$$(C_{0}, C_{1}) \\sim \\square_{\\mathfrak{C}}$$\n",
        "\n",
        "2. Transform each dimension of the coupled data through the CDF of the copula function $\\Phi_{\\mathfrak{C}}$ to yield \n",
        "   data distributed according to a Latent Uniform distribution $U$\n",
        "$$(U_{0}, U_{1}) = \\Phi_{\\mathfrak{C}}(C_{0}, C_{1})$$\n",
        "\n",
        "3. Transform each dimension of now-uniform data through the Inverse CDF of our chosen marginal distribution \n",
        "   $\\Phi^{-1}_{\\mathfrak{M}}$ to yield data distributed according to \"observed\" Marginal distribution(s) $M$\n",
        "$$(M_{0}, M_{1}) = \\Phi^{-1}_{\\mathfrak{M}}(U_{0}, U_{1})$$\n",
        "\n",
        "In the following slides we'll plot the distributions and describe the transformations. Also see project class\n",
        "`synthetic.create_copula.CopulaBuilder` for details\n",
        "\n",
        "Note we create $60$ observations split into 2 sets: $50$ for `train` (in-sample) and $10$ for `holdout` (out-of-sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'c_r': -0.7,\n",
              " 'c_cov': array([[ 1. , -0.7],\n",
              "        [-0.7,  1. ]]),\n",
              " 'm0_kind': 'lognorm',\n",
              " 'm1_kind': 'lognorm',\n",
              " 'm0_params': {'mu': 0.2, 'sigma': 0.5},\n",
              " 'm1_params': {'mu': 2.0, 'sigma': 1.0}}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cb = CopulaBuilder()\n",
        "df_all = cb.create(nobs=60)\n",
        "cb.ref_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "perm = RNG.permutation(df_all.index.values)\n",
        "df_train = df_all.loc[perm[:50]]\n",
        "df_holdout = df_all.loc[perm[50:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dtype</th>\n",
              "      <th>count_unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>sum</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ft</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>index: oid</th>\n",
              "      <td>object</td>\n",
              "      <td>50</td>\n",
              "      <td>i028</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>i059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c0</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.63</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.79</td>\n",
              "      <td>-2.13</td>\n",
              "      <td>-0.64</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>0.68</td>\n",
              "      <td>1.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c1</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.85</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.86</td>\n",
              "      <td>-2.12</td>\n",
              "      <td>-0.5</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u0</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.61</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u1</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.84</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m0</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>64.71</td>\n",
              "      <td>1.29</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1.72</td>\n",
              "      <td>2.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m1</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>493.00</td>\n",
              "      <td>9.86</td>\n",
              "      <td>8.25</td>\n",
              "      <td>0.89</td>\n",
              "      <td>4.47</td>\n",
              "      <td>7.84</td>\n",
              "      <td>12.93</td>\n",
              "      <td>45.47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c0x</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-5.38</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.91</td>\n",
              "      <td>-2.62</td>\n",
              "      <td>-0.58</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.34</td>\n",
              "      <td>1.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>c1x</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-5.52</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.99</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>0.54</td>\n",
              "      <td>2.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u0x</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.59</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>u1x</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.36</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m0x</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>63.91</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.91</td>\n",
              "      <td>1.22</td>\n",
              "      <td>1.45</td>\n",
              "      <td>3.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>m1x</th>\n",
              "      <td>float64</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>546.02</td>\n",
              "      <td>10.92</td>\n",
              "      <td>14.19</td>\n",
              "      <td>1.01</td>\n",
              "      <td>3.96</td>\n",
              "      <td>6.02</td>\n",
              "      <td>12.62</td>\n",
              "      <td>86.77</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              dtype count_unique   top freq     sum   mean    std   min   25%  \\\n",
              "ft                                                                              \n",
              "index: oid   object           50  i028    1     NaN    NaN    NaN  i000   NaN   \n",
              "c0          float64          NaN   NaN  NaN   -1.63  -0.03   0.79 -2.13 -0.64   \n",
              "c1          float64          NaN   NaN  NaN   -1.85  -0.04   0.86 -2.12  -0.5   \n",
              "u0          float64          NaN   NaN  NaN   24.61   0.49   0.26  0.02  0.26   \n",
              "u1          float64          NaN   NaN  NaN   24.84    0.5   0.27  0.02  0.31   \n",
              "m0          float64          NaN   NaN  NaN   64.71   1.29    0.5  0.42  0.89   \n",
              "m1          float64          NaN   NaN  NaN  493.00   9.86   8.25  0.89  4.47   \n",
              "c0x         float64          NaN   NaN  NaN   -5.38  -0.11   0.91 -2.62 -0.58   \n",
              "c1x         float64          NaN   NaN  NaN   -5.52  -0.11    1.0 -1.99 -0.62   \n",
              "u0x         float64          NaN   NaN  NaN   23.59   0.47   0.27   0.0  0.28   \n",
              "u1x         float64          NaN   NaN  NaN   23.36   0.47   0.29  0.02  0.27   \n",
              "m0x         float64          NaN   NaN  NaN   63.91   1.28   0.59  0.33  0.91   \n",
              "m1x         float64          NaN   NaN  NaN  546.02  10.92  14.19  1.01  3.96   \n",
              "\n",
              "             50%    75%    max  \n",
              "ft                              \n",
              "index: oid   NaN    NaN   i059  \n",
              "c0         -0.06   0.68   1.42  \n",
              "c1          0.06   0.56   1.82  \n",
              "u0          0.48   0.75   0.92  \n",
              "u1          0.52   0.71   0.97  \n",
              "m0          1.19   1.72   2.49  \n",
              "m1          7.84  12.93  45.47  \n",
              "c0x         -0.0   0.34   1.89  \n",
              "c1x        -0.21   0.54   2.46  \n",
              "u0x          0.5   0.63   0.97  \n",
              "u1x         0.42    0.7   0.99  \n",
              "m0x         1.22   1.45   3.14  \n",
              "m1x         6.02  12.62  86.77  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Shape: (50, 13), Memsize 0.0 MB'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "eda.describe(df_train, nobs=0, get_counts=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## 1.2 Visualise the Synthetic Observations"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "### 1.2.1 View the Latent Copula (an MvN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this forward-pass to create the synthetic data, we firstly create $50$ observations of\n",
        "of a 2-dimensional Multivariate Normal distribution with covariance $\\Sigma$\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "(C_{0}, C_{1}) &\\sim \\square_{\\mathfrak{C}} \\\\\n",
        "            &\\sim \\text{MultivariateNormal}(\\mu, \\Sigma, \\text{shape}=2)\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This forms our Latent Copula (a Gaussian), and this is where we could get creative and use any number of alternative\n",
        "copula functions from the literature (e.g. Clayton, Frank, Gumbel, etc) or even create our own: the copula marginals\n",
        "dont have to be the same distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
            "/var/folders/yr/x3q_mhvx0l5djfrgtr_06qcw0000gn/T/ipykernel_60354/2086184380.py:2: SyntaxWarning: invalid escape sequence '\\S'\n",
            "  txtadd=f'Latent Copula = $MvN(0, \\Sigma={cb.ref_vals[\"c_cov\"].flatten().tolist()})$')\n",
            "/var/folders/yr/x3q_mhvx0l5djfrgtr_06qcw0000gn/T/ipykernel_60354/2086184380.py:2: SyntaxWarning: invalid escape sequence '\\S'\n",
            "  txtadd=f'Latent Copula = $MvN(0, \\Sigma={cb.ref_vals[\"c_cov\"].flatten().tolist()})$')\n",
            "/Users/jon/workspace/oreum/oreum_core/oreum_core/eda/plot.py:915: SyntaxWarning: invalid escape sequence '\\m'\n",
            "  f\"$\\mu = {mn:,.{j}f}$, \"  # for {yhat_nm}\n",
            "/Users/jon/workspace/oreum/oreum_core/oreum_core/eda/plot.py:948: SyntaxWarning: invalid escape sequence '\\g'\n",
            "  f\"$P_{{@{{{q:.2f}}}}} \\geq {{{qv:.{j}f}}}$\"\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'QuadContourSet' object has no attribute 'collections'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43meda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_joint_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mft0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mft1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mc1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkde+scatter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtxtadd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLatent Copula = $MvN(0, \u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSigma=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref_vals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc_cov\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)$\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/workspace/oreum/oreum_core/oreum_core/eda/plot.py:468\u001b[0m, in \u001b[0;36mplot_joint_numeric\u001b[0;34m(data, ft0, ft1, hue, kind, height, kdefill, log, colori, nsamp, linreg, legendpos, palette_type, palette, eq, overplot, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m     _ \u001b[38;5;241m=\u001b[39m gd\u001b[38;5;241m.\u001b[39mplot_marginals(sns\u001b[38;5;241m.\u001b[39mrugplot, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrug_kws)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkde+scatter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 468\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_joint\u001b[49m\u001b[43m(\u001b[49m\u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkdeplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkde_kws\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m     _ \u001b[38;5;241m=\u001b[39m gd\u001b[38;5;241m.\u001b[39mplot_joint(sns\u001b[38;5;241m.\u001b[39mscatterplot, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscatter_kws)\n\u001b[1;32m    470\u001b[0m     _ \u001b[38;5;241m=\u001b[39m gd\u001b[38;5;241m.\u001b[39mplot_marginals(sns\u001b[38;5;241m.\u001b[39mrugplot, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrug_kws)\n",
            "File \u001b[0;32m~/miniforge/envs/oreum_copula/lib/python3.12/site-packages/seaborn/axisgrid.py:1826\u001b[0m, in \u001b[0;36mJointGrid.plot_joint\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inject_kwargs(func, kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hue_params)\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseaborn\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1826\u001b[0m     \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1827\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1828\u001b[0m     func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/miniforge/envs/oreum_copula/lib/python3.12/site-packages/seaborn/distributions.py:1731\u001b[0m, in \u001b[0;36mkdeplot\u001b[0;34m(data, x, y, hue, weights, palette, hue_order, hue_norm, color, fill, multiple, common_norm, common_grid, cumulative, bw_method, bw_adjust, warn_singular, log_scale, levels, thresh, gridsize, cut, clip, legend, cbar, cbar_ax, cbar_kws, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m     p\u001b[38;5;241m.\u001b[39mplot_univariate_density(\n\u001b[1;32m   1718\u001b[0m         multiple\u001b[38;5;241m=\u001b[39mmultiple,\n\u001b[1;32m   1719\u001b[0m         common_norm\u001b[38;5;241m=\u001b[39mcommon_norm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1726\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplot_kws,\n\u001b[1;32m   1727\u001b[0m     )\n\u001b[1;32m   1729\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1731\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_bivariate_density\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommon_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommon_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_singular\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcbar_ax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcbar_ax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcbar_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcbar_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimate_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimate_kws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ax\n",
            "File \u001b[0;32m~/miniforge/envs/oreum_copula/lib/python3.12/site-packages/seaborn/distributions.py:1192\u001b[0m, in \u001b[0;36m_DistributionPlotter.plot_bivariate_density\u001b[0;34m(self, common_norm, fill, levels, thresh, color, legend, cbar, warn_singular, cbar_ax, cbar_kws, estimate_kws, **contour_kws)\u001b[0m\n\u001b[1;32m   1185\u001b[0m cset \u001b[38;5;241m=\u001b[39m contour_func(\n\u001b[1;32m   1186\u001b[0m     xx, yy, density,\n\u001b[1;32m   1187\u001b[0m     levels\u001b[38;5;241m=\u001b[39mdraw_levels[key],\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcontour_kws,\n\u001b[1;32m   1189\u001b[0m )\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables:\n\u001b[0;32m-> 1192\u001b[0m     \u001b[43mcset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollections\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_label(label)\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;66;03m# Add a color bar representing the contour heights\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Note: this shows iso densities, not iso proportions\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;66;03m# See more notes in histplot about how this could be improved\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cbar:\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'QuadContourSet' object has no attribute 'collections'"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 3 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "height": 421,
              "width": 428
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "f = eda.plot_joint_numeric(data=df_train, ft0='c0', ft1='c1', kind='kde+scatter', \n",
        "            txtadd=f'Latent Copula = $MvN(0, \\Sigma={cb.ref_vals[\"c_cov\"].flatten().tolist()})$')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Note the standard `Normal(0,1)` scaling on the marginals\n",
        "+ Note the empirically-observed correlation $\\rho \\approx -0.7$ as defined in `c_cov`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "### 1.2.2 View the Uniform-Transformed Marginals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "In this forward-pass to create the synthetic data, next we pass each dimension of the Latent Copula $C$ through the \n",
        "CDF of it's own function $\\Phi_{\\mathfrak{C}}$ to get a Latent Uniform distribution $U$\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "(U_{0}, U_{1}) &= \\Phi_{\\mathfrak{C}}(C_{0}, C_{1}) \\\\\n",
        "            &= \\text{NormalCDF}(C_{0}, C_{1})\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Regardless of the latent copula, this intermediate step will result in 2 Uniform marginals (which still have covariance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "f = eda.plot_joint_numeric(data=df_train, ft0='u0', ft1='u1', kind='kde+scatter', colori=1, \n",
        "        txtadd='Latent Uniform Marginals with Copula Covariance')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Now the marginals are uniform, but the correlation remains"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "### 1.2.3 View the Observed Marginals `m0`, `m1` (post transformation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "In this forward-pass to create the synthetic data, next we pass each dimension of the Latent Uniform $U$ through the \n",
        "Inverse CDF of the marginal distribution $\\Phi^{-1}_{\\mathfrak{M}}$ to get the Marginal distribution(s) in $M$\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "(M_{0}, M_{1}) &= \\Phi^{-1}_{\\mathfrak{M}}(U_{0}, U_{1}) \\\\\n",
        "                &= \\text{LogNormalInvCDF}(U_{0}, U_{1})\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "The marginal distribution(s) $M$ can be anything. In practice we tend to use right-tailed distributions in the \n",
        "Exponential family, here a LogNormal. We can, of course, use different distributions on each marginal - there's no \n",
        "constraint to be the same - but we use the same ones here. This is the data that we would observe in the \n",
        "real-world dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "f = eda.plot_joint_numeric(data=df_train, ft0='m0', ft1='m1', kind='kde+scatter', colori=2, \n",
        "            txtadd='Observed Marginals with Copula Covariance')\n",
        "fqn = figio.write(f, fn='000_jointplot_corr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "**Observe**\n",
        "\n",
        "+ Marginals now have unique long-tail distributions, and the correlation remains"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "### 1.2.4 View the Marginals $Mx$ if they were synthesized without a Copula"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "In project class `synthetic.create_copula.CopulaBuilder` we also synthesize uncorrelated observations using the same\n",
        "transformation and final marginals $M$, so that we can visually compare the different effects. \n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "(C^{\\chi}_{0}, C^{\\chi}_{1}) &\\sim \\text{Normal}(\\mu, \\sigma, \\text{shape}=2) \\\\\n",
        "(U^{\\chi}_{0}, U^{\\chi}_{1}) &= \\text{NormalCDF}(C^{\\chi}_{0}, C^{\\chi}_{1}) \\\\\n",
        "(M^{\\chi}_{0}, M^{\\chi}_{1}) &= \\text{LogNormalInvCDF}(U^{\\chi}_{0}, U^{\\chi}_{1}) \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Uncorrelated marginals $M^{\\chi}$ individually look the same as $M$. We have to look at the joint distribution to see the difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "f = eda.plot_joint_numeric(data=df_train, ft0='m0x', ft1='m1x', kind='kde+scatter', colori=3, \n",
        "            txtadd='Observed Marginals without Copula Covariance')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**\n",
        "\n",
        "+ Spherical joint distribution, no correlation between our marginals here"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "### 1.2.5 Overplot Marginals Correlated ($M$) vs Uncorrelated ($M^{\\chi}$) to Highlight the Differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "dfp = pd.concat((df_train[['m0', 'm1']], df_train[['m0x', 'm1x']]\\\n",
        "                 .rename(columns={'m0x':'m0', 'm1x': 'm1'})),\n",
        "                axis=0, ignore_index=True)\n",
        "dfp['corr_kind'] = np.repeat(['y_corr', 'y_uncorr'], repeats=len(df_train))\n",
        "f = eda.plot_joint_numeric(\n",
        "    data=dfp, ft0='m0', ft1='m1', hue='corr_kind', kind='kde', kdefill=False, colori=2,\n",
        "    txtadd='Observed marginals with / without Copula Covariance')\n",
        "fqn = figio.write(f, fn='000_jointplot_corr_vs_uncorr')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "**Observe**\n",
        "\n",
        "+ The marginals look almost identical, but the joint distribution is very different\n",
        "+ We might say _\"so what?\"_ because we can always jointplot our marginals $M$ and see that there is correlation\n",
        "+ The huge impact is that these lead to a very different **joint product** $y$..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## 1.3 Compare the Impact on Joint Product $y$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "If we build a model $\\mathcal{H}$ that fits to marginals $M$, but does not account for the correlation, $\\mathcal{H}$\n",
        "will behave as if we fit it on uncorrelated marginals $M^{\\chi}$. The predicted differences in $M$ and $M^{\\chi}$ won't \n",
        "look too different on the marginals, but the joint products $y = M_{0} \\cdot M_{1}$ vs \n",
        "$y^{\\chi} = M^{\\chi}_{0} \\cdot M^{\\chi}_{1}$ can become very different:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "dfp['joint'] = dfp[['m0', 'm1']].product(axis=1)\n",
        "pal = sns.color_palette(['C2', 'C3'])\n",
        "f = eda.plot_smrystat_grp(dfp, grp='corr_kind', val='joint', palette=pal)\n",
        "fqn = figio.write(f, fn='000_y_corr_vs_uncorr')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "**Observe:**\n",
        "\n",
        "+ This customer diagnostic combination plot shows: \n",
        "  + Pointplot (left): The [bootstrapped](https://sedar.co/posts/bootstrap-primer/) sums $\\sum_{i}y_{i}$ vs $\\sum_{i}y^{\\chi}_{i}$\n",
        "  + Boxplot (center): The individual values $y_{i}$ vs $y^{\\chi}_{i}$\n",
        "  + Countplot (right): The counts of observations $i$\n",
        "+ The (bootstrapped) sum of `y_uncorr` ($\\mu \\approx 700$) is almost always much higher than for `y_corr` ($\\mu \\approx 500$)\n",
        "+ This shows that if our model $\\mathcal{H}$ were to estimate marginals correctly but ignore the covariance, it would erroneously mis-estimate the joint distribution total value $y$. Here that mistake is to overestimate."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "#### View the overestimate $\\delta = \\sum_{i}y^{\\chi}_{i} - \\sum_{i}y_{i}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "Let's view the bootstapped overestimate `delta = y_uncorr = y_corr`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "idx = dfp['corr_kind'] == 'y_corr'\n",
        "dfpp = pd.DataFrame({'delta': dfp.loc[~idx, 'joint'].values - dfp.loc[idx, 'joint'].values}, index=df_train.index)\n",
        "g = eda.plot_smrystat(dfpp, val='delta', txtadd='joint product value')\n",
        "fqn = figio.write(f, fn='000_y_delta')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "**Observe:**\n",
        "\n",
        "If we imagine this to be a portfolio of $50$ policies, and the value of interest is an Expected Loss Cost \n",
        "$y == \\mathbb{E}_{\\text{loss}}$, and the units are dollars, then: \n",
        "+ If we were to use a model that ignores covariance, we might get a portfolio estimate of $\\mathbb{E}_{loss} \\approx 200$ dollars \n",
        "  **higher** than if we were to use a better model that handles covariance with a copula function\n",
        "+ This overestimate is a substantial $\\frac{700}{500} \\approx \\mathbb{+40\\%}$ and would likely make the difference between profitable \n",
        "  pricing / accurate reserving, or greatly loss-making business over the portfolio."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "# 2. Brief Technical Summary: The Copula Model designed in this Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "Again, this **Intro** is for verbal presentation and discussion purposes only - ideally followed by a deeper technical \n",
        "walkthrough of the project in a long-form style. Because this project is a reference, it contains huge amounts of detail \n",
        "which is not worthwhile to summarise too much. \n",
        "\n",
        "The interested reader should refer to the project notebooks where state the architecture in full, we evaluate the \n",
        "behaviour and performance of the models in a consistent Bayesian workflow, including several state-of-the-art methods\n",
        "unavailable to conventional max-likelihood / machine-learning models.\n",
        "\n",
        "Here we can can highlight a very tangible impact of our results of using a Copula model (`ModelA2`) vs a Naive model \n",
        "(`ModelA0`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## 2.1 Brief Orientation on Model Workflow and Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "### General Approach\n",
        "\n",
        "+ We create a synthetic dataset with 60 observations: these have exogenous values on 2 marginals $M_{0}$, $M_{1}$\n",
        "+ We create 3 models of increasing sophistication to estimate $\\hat{M_{0}}$, $\\hat{M_{1}}$ and thus the joint product \n",
        "  $\\hat{y} = \\hat{M_{0}} \\cdot \\hat{M_{1}}$\n",
        "+ The simplest naive model (`ModelA0`) does not include a copula function, and the most sophisticated model `ModelA2` does"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "\n",
        "+ We define a training set of 50 random observations, fit the models, and view the forecasted predictions on a holdout \n",
        "  set of 10 observations\n",
        "+ We fully evaluate the models in the project notebooks using a variety of sophisticated techniques including In-sample\n",
        "  Prior & Posterior Retrodictive ECDF plots, LOO-PIT calculations & plots, and more convential coverage, RSME and R2 \n",
        "  calculations. This forecast on the holdout is _not_ a formal model evaluation\n",
        "+ However for discussion and elucidation we can plot the [bootstrapped](https://sedar.co/posts/bootstrap-primer/) sum\n",
        "  of the actual values $\\sum{y}_{\\text{holdout}}$ and compare to the posterior predictions $\\sum{\\hat{y}}_{\\text{holdout}}$\n",
        "  of the two models "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "### General Architecture\n",
        "\n",
        "In contrast to the \"forward-pass\" that we use to synthesize the data, for the model we must of course start with the \n",
        "only data that we have (the observed marginals $M$) and work in a \"backwards-pass\" toward the copula.\n",
        "\n",
        "1. Define 2 marginal distributions $(\\mathfrak{M}_{0}, \\mathfrak{M}_{1})$ (here for convenience we use the same family \n",
        "   (Lognormals) for each, so we will represent as simply $\\mathfrak{M}$). Each marginal is parameterised by a linear \n",
        "   submodel $\\beta^{T}\\mathbb{x}_{ij}$ to allow linear regression onto selected features $j$ \n",
        "$$\\mathfrak{M} = \\text{LogNormal}(\\mu=\\beta^{T}\\mathbb{x}_{ij}, \\sigma)$$\n",
        "   \n",
        "2. Transform each dimension of the observed marginal data $M$ through the CDF of the marginal distribution(s) to yield \n",
        "   data distributed according to a Latent Uniform distribution $U$\n",
        "$$(U_{0}, U_{1}) = \\Phi_{\\mathfrak{M}}(M_{0}, M_{1})$$\n",
        "\n",
        "3. Transform each dimension of now-uniform data $U$ through the Inverse CDF of the copula distribution(s) \n",
        "   $(\\mathfrak{C}_{0}, \\mathfrak{C}_{1})$ (here for convenience we use the same family (Normal aka a Gaussian Copula) \n",
        "   for each, so we will represent as simply $\\mathfrak{C}$)\n",
        "$$(C_{0}, C_{1}) = \\Phi^{-1}_{\\mathfrak{C}}(U_{0}, U_{1})$$\n",
        "\n",
        "4. Evidence the transformed data $C$ against the copula function $\\log \\mathcal{L}\\ \\mathfrak{C}$ \n",
        "5. For stability and correctness, we also evidence at the marginals and minimise a Jacobian adjustment on the \n",
        "   double-transformed data.\n",
        "6.  **Importantly**, and unlike other model specifications in the Bayesian literature, we preserve the full posterior\n",
        "   distribution(s) all the way through the model specification, without ever having to collapse to point estimates\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "### Plate Notation Diagram\n",
        "\n",
        "Refer to Notebook `102_ModelA2.ipynb` and project class `models.copula.ModelA2` for the full details. Here we will just\n",
        "show the plate notation of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "figio.read(fn='../data/models/graph_mdla2_v120_dfx_train.png', \n",
        "        title='Plate Notation of Copula ModelA2', figsize=(12, 7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "This advanced, fully Bayesian architecture allows for:\n",
        "+ Regression via linear submodels $\\beta^{T}\\mathbf{x}$ on the marginals of `mhat`\n",
        "+ Efficient covariance via an $\\text{LKJCholeskyCovariance}$ structure\n",
        "+ A natural transformation from `M -> U -> C` including Jacobian Adjustment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## 2.2 Compare Estimated $\\hat{y}$ `ModelA0` vs `ModelA2`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "### `ModelA0`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This model sets a baseline for performance: it uses the same marginals but does not have a copula. This is\n",
        "\"the best that one could do\" with a naive non-copula architecture, and the performance / results are analogous to \n",
        "$M^{\\chi}$ that we discussed in $\\S1$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "figio.read(fn='100_2_8_4_ppc_holdout_y_boxplot_mdla0_v1_3_0_dfx_holdout.png', figsize=(12, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Now we can clearly see the impact: although the in-sample model fit was acceptable, the combined value $y$ is way\n",
        "  off, because this model ignores copula correlation between the marginals\n",
        "+ The mean of $\\sum_{i}{\\hat{y}}_{i}$ is $\\mu = 133$, is very different (and sits outside of) the bootstrapped sum of \n",
        "  the actual data $\\sum_{i}{\\hat{y}}_{i}$ which has a mean $\\mu = 96$\n",
        "+ Comparing means we have a $\\frac{133}{96} \\approx 39\\%$ overestimate!\n",
        "+ We do see that the PPC distribution envelops the bootstrapped actual data, which is promising, and means the model \n",
        "  wouldn't necessarily be wrong to use, but there is clearly room to improve!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "### `ModelA2`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is our most advanced model with a copula architecture: the performance / results are analogous to \n",
        "$M$ that we discussed in $\\S1$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "figio.read(fn='102_2_8_4_ppc_holdout_y_boxplot_mdla2_v1_2_0_dfx_holdout.png', figsize=(12, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Now we can clearly see the impact: the Jacobian adjustment has allowed `mdla2` to estimate a much more precise and \n",
        "  accurate value for $\\hat{y}$\n",
        "+ The mean of $\\sum_{i}{\\hat{y}}_{i}$ is $\\mu = 103$, and falls within the bootstrapped sum for the actual data $\\sum_{i}{\\hat{y}}_{i}$\n",
        "  which has a mean $\\mu = 96$\n",
        "+ Comparing means, we get $\\frac{103}{96} \\approx 7\\%$ overestimate\n",
        "+ This is substantially better than `mdla0`, and also meaningfully improves on `mdla1`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "### `ModelA2` vs `ModelA0`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "In the above, we see a reduction in the mean overestimate of $y$ from $39\\%$ down to $7\\%$: **a 32 percentage point drop**\n",
        "\n",
        "This is a **huge difference** on this very small and simple dataset, and found only by correctly modelling the covariance \n",
        "using a copula and a sophisticated model architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "source": [
        "## 2.3 Supercharged Predictions with Quantified Uncertainty: Exceedance Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "Now we pull back to demonstrate the power and utility of using a Bayesian model in the first place: because the predicted\n",
        "output values individually & jointly have **quantified uncertainty** aka empirical probability. We can sum these and \n",
        "create an **Exceedance Curve (1 - ECDF)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "outputs": [],
      "source": [
        "figio.read(fn='102_2_8_4_ppc_holdout_y_exceedance_mdla2_v1_2_0_dfx_holdout.png', figsize=(12, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "fragment"
        }
      },
      "source": [
        "We can read this curve _vertically_ to determine the empirical probability of achieving a particular value $y$:\n",
        "+ $P(\\sum{\\hat{y}_{i}} > 150) \\lt 0.05$: i.e. if we're worried about $\\sum{\\hat{y}_{i}} > 150$, we can slightly relax \n",
        "  because the probability is less than 1-in-20\n",
        "+ $P(\\sum{\\hat{y}_{i}} > 200) \\lt 0.01$: i.e. if we're worried about $\\sum{\\hat{y}_{i}} > 200$, we can relax \n",
        "  because the probability is less than 1-in-100\n",
        "\n",
        "We can read this curve _horizontally_ to determine the value $y$ at a particular probability:\n",
        "+ $P_{@0.5} \\geq 100$: i.e. 50% of all outcomes occur at $\\sum{\\hat{y}_{i}} \\leq 100$\n",
        "+ $P_{@0.01} \\geq 178$: i.e. 99% of all outcomes occur at $\\sum{\\hat{y}_{i}} \\leq 178$\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "slideshow": {
          "slide_type": "skip"
        }
      },
      "outputs": [],
      "source": [
        "%load_ext watermark\n",
        "%watermark -a \"jonathan.sedar@oreum.io\" -udtmv -iv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "source": [
        "### Next Steps\n",
        "\n",
        "Now the interested reader should dig into the Notebooks in project reference\n",
        "[`oreum_copula`](https://github.com/oreum-industries/oreum_copula)\n",
        "\n",
        "There we demonstrate the full E2E workflow for models of increasing sophistication, \n",
        "including several state-of-the-art methods unavailable to conventional \n",
        "max-likelihood / machine-learning models.\n",
        "\n",
        "+ `100_ModelA0.ipynb`: Core (naive) architecture: Create priors, marginal likelihoods, but no copula\n",
        "+ `101_ModelA1.ipynb`: Partial architecture (extends ModelA0): Include Gaussian copula (w/ Jacobian adjustment), and several technical innovations to let `pymc` work with the transformations\n",
        "+ `102_ModelA2.ipynb`: Full architecture (extends ModelA1): Include Jacobian Adjustment on transformed observations\n",
        "\n",
        "<a href='https://oreum.io'><img src='../assets/img/Oreum_wordmark_black_right_aligned_S.png' width='300px' style=\"float: right;\"/></a><div style=\"clear:both\"/>\n",
        "\n",
        "---\n",
        "**[Oreum Industries](https://oreum.io/) &copy; 2024**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "oreum_copula",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
