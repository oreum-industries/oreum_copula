{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Oreum Industries Internal Project, 2024Q1**\n",
        "\n",
        "---\n",
        "\n",
        "# 001_MRE_ModelA0.ipynb\n",
        "\n",
        "### Oreum Copula Demo in `oreum_copula`\n",
        "\n",
        "Implementation of Bayesian Copula-Based Expected Loss Cost Forecasting. \n",
        "We use highly advanced Bayesian inference techniques and a Bayesian workflow, \n",
        "specifically using the `pymc` & `arviz` ecosystem.\n",
        "\n",
        "Here we demonstrate an E2E workflow for novel models of increasing sophistication.\n",
        "We evaluate the behaviour and performance of the models throughout the workflows,\n",
        "including several state-of-the-art methods unavailable to conventional\n",
        "max-likelihood / machine-learning models.\n",
        "\n",
        "**In this Notebook:**\n",
        "\n",
        "Build & test `ModelA0`, a naive version of the core project architecture **without a copula**.\n",
        "To demonstrate some of the core aspects and make the case for needing a copula.\n",
        "\n",
        "\n",
        "## Contents\n",
        "\n",
        "+ [Setup](#Setup)\n",
        "\n",
        "\n",
        "+ [2. Define & Build Model, Sample Prior & Evaluate](#2.-Define-&-Build-Model-&-Sample-Prior-&-Evaluate)\n",
        "\n",
        "+ [3. Sample Posterior & Evaluate](#3.-Sample-Posterior-&-Evaluate)\n",
        "\n",
        "+ [4. Evaluate Posterior Parameters](#4.-Evaluate-Posterior-Parameters)\n",
        "\n",
        "+ [5. Predict Out-of-Sample (Holdout Set)](#5.-Predict-Out-of-Sample-(Holdout-Set))\n",
        "\n",
        "+ [6. Evaluate Predictions (Holdout Set)](#6.-Evaluate-Predictions-(Holdout-Set))\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from copy import deepcopy\n",
        "from pathlib import Path\n",
        "\n",
        "import arviz as az\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import Markdown, display\n",
        "from pyprojroot.here import here\n",
        "\n",
        "# prepend local project src files\n",
        "module_path = here('src').resolve(strict=True)\n",
        "if str(module_path) not in sys.path:\n",
        "    sys.path.insert(0, str(module_path))    # sys.path.append(str(module_path))\n",
        "\n",
        "# autoreload local modules to allow dev-js\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "from oreum_core import eda\n",
        "from oreum_core import model_pymc as mt\n",
        "\n",
        "from engine import app_logger\n",
        "from engine.trainer import Trainer\n",
        "from model.model_a import ModelA0\n",
        "from synthetic.create_copula import CopulaBuilder\n",
        "\n",
        "import warnings  # isort:skip\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)  # isort:skip"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Notebook config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "sns.set(style='darkgrid', palette='muted', context='notebook', \n",
        "        rc={'savefig.dpi':300, 'figure.figsize': (12, 3)})\n",
        "\n",
        "log = app_logger.get_logger('000_Example_ModelA0', notebook=True)\n",
        "_ = app_logger.get_logger('oreum_core', notebook=True)\n",
        "# _ = app_logger.get_logger('py.warnings', notebook=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Local Functions and Global Vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RSD = 42\n",
        "rng = np.random.default_rng(seed=RSD)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Connections and Helper Objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "figio = eda.FigureIO(here(Path('plots')).resolve(strict=True))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 0. Synthesize Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "See `000_MRE_EDA.ipynb` for details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cb = CopulaBuilder()\n",
        "df_all = cb.create(nobs=120)\n",
        "print(cb.ref_vals)\n",
        "perm = rng.permutation(df_all.index.values)\n",
        "df_train = df_all.loc[perm[:100]]\n",
        "df_holdout = df_all.loc[perm[100:]]\n",
        "# eda.describe(df_train, nobs=3, get_counts=False)\n",
        "eda.display_ht(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Model Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.0 Model Spec\n",
        "### Estimate Marginals\n",
        "\n",
        "#### M0\n",
        "\n",
        "\\begin{align}\n",
        "    \\beta_{m0}^{j1} &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n",
        "    \\sigma_{m0} &\\sim \\text{InverseGamma}(\\alpha, \\beta) \\\\\n",
        "    \\mathfrak{m0}_{y}^{j0} &\\sim \\text{LogNormal}(\\mu=\\beta_{m0}^{T}\\vec{x}_{y}^{j0}, \\sigma=\\sigma_{m0}) \\\\\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "#### M1\n",
        "\n",
        "\\begin{align}\n",
        "    \\beta_{m1}^{j1} &\\sim \\text{Normal}(\\mu, \\sigma) \\\\\n",
        "    \\sigma_{m1} &\\sim \\text{InverseGamma}(\\alpha, \\beta) \\\\\n",
        "    \\mathfrak{m1}_{y}^{j1} &\\sim \\text{LogNormal}(\\mu=\\beta_{m1}^{T}\\vec{x}_{y}^{j1}, \\sigma=\\sigma_{m1}) \\\\\n",
        "\\end{align}\n",
        "\n",
        "Where:\n",
        "\n",
        "+ We use the same distribution family for each marginal (a LogNormal), \n",
        "  because we want to keep this example simple\n",
        "+ We indicate and observations as $y$ e.g. $\\vec{x}_{y}^{j0}$\n",
        "+ The linear models for the regression on each LogNormal marginal are exponentiated \n",
        "  for convenience, so that $\\beta_{m}^{T}\\vec{x}^{j}$ becomes the median value\n",
        "+ Features in $\\vec{x}^{j1}$ and $\\vec{x}^{j2}$ are each chosen from the full \n",
        "  set of features $j \\in m$\n",
        "+ In our synthetic data here, we actually have no features $m$, so $j0$ and $j1$\n",
        "  are both intercept-only\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### ~~Estimate Copula~~\n",
        "\n",
        "This model does not fit a copula to the marginals. See NBs 101 and 102 for detail\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Transform observations for linear sub-models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Normally, we would use `patsy` to transform the \"raw\" (synthetic) data created above into two separate design-matrices (for marginal 1 and marginal 2) each according to a linear model. This is total overkill here, so we'll keep life much simpler.\n",
        "\n",
        "We have no features for `m0` and `m1`, so the linear sub-models have to be intercept-only. Here we must also forget anything we know about the construction of the synthetic data, this is all we have."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3.1 Train set (in-sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eda.describe(df_train[['m0', 'm1']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfx_m0_train = df_train[['m0']].copy()\n",
        "dfx_m0_train['intercept'] = 1.0\n",
        "eda.display_ht(dfx_m0_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfx_m1_train = df_train[['m1']].copy()\n",
        "dfx_m1_train['intercept'] = 1.0\n",
        "eda.display_ht(dfx_m1_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3.2 holdout set (out-of-sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eda.describe(df_holdout[['m0', 'm1']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfx_m0_holdout = df_holdout[['m0']].copy()\n",
        "dfx_m0_holdout['intercept'] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfx_m1_holdout = df_holdout[['m1']].copy()\n",
        "dfx_m1_holdout['intercept'] = 1.0"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Define & Build Model, Sample Prior & Evaluate"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.0.1 Build helper objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fqns = dict(\n",
        "    fp_mdl=here(Path('data', 'models', 'mdla')).resolve(strict=True),\n",
        "    fp_plots = here(Path('plots')).resolve(strict=True),\n",
        "    fn_mdl='idata_mdla0',\n",
        ")\n",
        "trainer = Trainer(fqns=fqns)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.0.2 Sanity-check Lognorm Implementations `scipy` vs `pymc`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mt.sanity_check_lognorm(cb.ref_vals['m0_params']['mu'], \n",
        "                        cb.ref_vals['m1_params']['sigma'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Build Model Object"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**NOTE:** Model imported from `src.model.copula.model_a.py` where it is fully defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl = ModelA0(obs_m0=dfx_m0_train, obs_m1=dfx_m1_train)\n",
        "mdl.build()\n",
        "_ = [display(Markdown(s)) for s in mt.print_rvs(mdl)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fqn = trainer.mdlio.write_graph(mdl)  # output model graph to prove built\n",
        "f = eda.display_image_file(fqn, \n",
        "    title=f'Model architecture: {mdl.name} {mdl.version}', figsize=(12, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Quick pass with [`model.debug()`](https://github.com/pymc-devs/pymc/blob/5f29b255127088abc552079fd03c40eb19d83bdd/pymc/model/core.py#L1739) and [`pymc.testing.assert_no_rvs`](https://github.com/pymc-devs/pymc/blob/c3f93bad3db7c34c12e4c51e1e7fb88f62c97020/pymc/testing.py#L952)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Random:\\n')\n",
        "mdl.model.debug(fn='random', verbose=True)\n",
        "\n",
        "# known failure for potentials: https://github.com/pymc-devs/pymc/issues/6966\n",
        "print('logP:\\n')\n",
        "mdl.model.debug(fn='logp', verbose=True)\n",
        "\n",
        "from pymc.testing import assert_no_rvs\n",
        "\n",
        "assert_no_rvs(mdl.model.logp())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Sample Prior Predictive & Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl.sample_prior_predictive(var_names=mdl.rvs_marg + mdl.rvs_ppc, replace=True)       \n",
        "mdl.idata"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2.1 Hyperpriors on Marginals for Feature Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get ref values from copula builder\n",
        "refs = [cb.ref_vals['m0_params']['mu'], cb.ref_vals['m0_params']['sigma'], \n",
        "        cb.ref_vals['m1_params']['mu'], cb.ref_vals['m1_params']['sigma']\n",
        "        ]\n",
        "f = mt.facetplot_krushke(mdl=mdl, group='prior', txtadd='hyperpriors on marginals',\n",
        "        rvs=mdl.rvs_marg, ref_vals=refs, m=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Priors contain the reference values, seems reasonable"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2.2 ~~Copula Structure~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No copula in this naive model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2.3 Plot ECDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = mt.plot_ppc(mdl, group='prior', data_pairs={'yhat':'yhat'}, \n",
        "                flatten=['oid'], observed_rug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Terrible fit as expected, but the range is valid"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Sample Posterior & Evaluate"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Sample Posterior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if RELOAD_IDATA:\n",
        "#     mdl.update_idata(trainer.mdlio.read_idata(fqn=trainer.fqns['fqn_idata']))\n",
        "# else:\n",
        "#     mdl.sample()\n",
        "#     mdl.sample_posterior_predictive(store_ppc=True, ppc_insample=True, \n",
        "#                                     var_names=mdl.rvs_ppc)\n",
        "#     trainer.mdlio.write_idata(mdl=mdl)\n",
        "\n",
        "# mdl.idata"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 View Diagnostics"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2.1 Plot Posterior Traces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = mt.plot_trace(mdl=mdl, rvs=mdl.rvs_marg, kind='trace')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "    \n",
        "+ Traces appear reasonably well-mixed\n",
        "+ Posterior distributions reasonably central"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2.2 Summarize Posterior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mt.get_summary(mdl=mdl, rvs=mdl.rvs_marg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Parameters are all fairly well-behaved: `ess_bulk` is good, `r_hat` is good"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2.3 Plot Energy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = mt.plot_energy(mdl=mdl)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ BFMI above 0.3, so [apparently reasonable](https://arxiv.org/pdf/1701.02434.pdf)\n",
        "+ A little messy though, not symmetric"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 Evaluate In-Sample PPC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3.1 Visually Compare In-Sample Predictions to Observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_train[['m0', 'm1']].describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# eda.display_ht(mt.get_summary(mdl=mdl, rvs=mdl.rvs_ppc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the real observed again\n",
        "f = eda.plot_joint_numeric(data=df_train, ft0='m0', ft1='m1', kind='kde+scatter', colori=2, \n",
        "            subtitle='Observed Marginals with Copula Correlation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3.1 View In-Sample PPC Joint `yhat0`, `yhat1`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rv = 'yhat'\n",
        "cols = mdl.coords[f'{rv}_nm']\n",
        "x = az.extract(mdl.idata, group='posterior_predictive', var_names=rv).values\n",
        "dfp_y = pd.DataFrame(np.nanmean(x, axis=2), columns=cols)\n",
        "f = eda.plot_joint_numeric(data=dfp_y, ft0=cols[0], ft1=cols[1], kind='kde+scatter', \n",
        "            colori=2, subtitle='In-Sample Posterior Predictive Marginals (mean)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Joint distribution looks spherical - does not have the covariance structure of\n",
        "  the actual data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Quantiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qs = [0.03, 0.25, 0.5, 0.75, 0.97]\n",
        "dfp_q = pd.DataFrame(np.quantile(x, qs, axis=2).reshape(len(qs)*mdl.n, 2), columns=cols)\n",
        "dfp_q['q'] = np.repeat([f'{q}'  for q in qs], mdl.n)\n",
        "f = eda.plot_joint_numeric(data=dfp_q, ft0=cols[0], ft1=cols[1], hue='q', kind='kde',\n",
        "            legendpos='lower right',\n",
        "            subtitle='In-Sample Posterior Predictive Marginals (quantiles)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**\n",
        "\n",
        "+ The PPC quantile range covers the range of the observed data quite well\n",
        "+ The extremes quantiles are still very tightly grouped - variance well managed?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3.2 Evaluate via ECDF Plot (In-Sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = mt.plot_ppc(mdl, group='posterior', data_pairs={'yhat': 'yhat'}, \n",
        "                flatten=['oid'], observed_rug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Bulk: reasonably good fit\n",
        "+ Tails: reasonable fit but heavier than observed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3.3 Evaluate via LOO-PIT Plot (In-Sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = mt.plot_loo_pit(mdl, data_pairs={'yhat':'yhat'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**\n",
        "\n",
        "+ Very slight overdispersion, but otherwise a pretty good fit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3.4 ~~Compare Log-Likelihood vs other models~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No other models yet"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Evaluate Posterior Parameters"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also in this demo notebook we can evaluate parameter recovery"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Hyperpriors on Marginals for Feature Regression"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1.1 Univariate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get ref values from copula builder\n",
        "refs = [cb.ref_vals['m0_params']['mu'], cb.ref_vals['m1_params']['mu'], \n",
        "        cb.ref_vals['m0_params']['sigma'], cb.ref_vals['m1_params']['sigma']\n",
        "        ]\n",
        "f = mt.facetplot_krushke(mdl=mdl, txtadd='hyperpriors on marginals',\n",
        "        rvs=mdl.rvs_marg, ref_vals=refs, m=2, hdi_prob=0.50)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Parameter recovery looks good for `m0_b`, `m1_b`: reference values fall into the 50% HDI of the posterior estimates\n",
        "+ Parameter recovery looks good for `s1`, but not `s0`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1.2 Bivariate Pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "refsd = {\n",
        "    'm0_b\\nintercept': cb.ref_vals['m0_params']['mu'], \n",
        "    'm1_b\\nintercept': cb.ref_vals['m1_params']['mu'],\n",
        "    'm_s\\ns0': cb.ref_vals['m0_params']['sigma'], \n",
        "    'm_s\\ns1' :cb.ref_vals['m1_params']['sigma']\n",
        "    }\n",
        "f = mt.pairplot_corr(mdl=mdl, rvs=mdl.rvs_marg, ref_vals=refsd)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Another view of the parameter recovery, which seems:\n",
        "  + good for `m0_b` and `m1_b`\n",
        "  + reasobale for `m_s`\n",
        "+ But no correlation between `m0_b` and `m1_b`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 ~~Copula Structure~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Predict Out-of-Sample (Holdout Set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.1 Sample PPC holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# replace obs with dfx_pholdout and build\n",
        "mdl.replace_obs({'obs_m0': dfx_m0_holdout, 'obs_m1':dfx_m1_holdout})\n",
        "mdl.build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fqn = trainer.mdlio.write_graph(mdl, txtadd='holdout')  # output model graph to prove rebuilt\n",
        "f = eda.display_image_file(fqn, \n",
        "    title=f'Rebuilt model architecture for holdout: {mdl.name} {mdl.version}', figsize=(12, 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idata_holdout = mdl.sample_posterior_predictive(store_ppc=False, \n",
        "        ppc_insample=True,  # hack to ensure output is named posterior_predictive so we can do EDCF\n",
        "        var_names=mdl.rvs_ppc)\n",
        "\n",
        "GROUP = 'posterior_predictive'  # predictions\n",
        "\n",
        "idata_holdout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.2 Plot holdouts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calling back to **1.2.6 Compare the Impact on Joint Distribution** we might consider the PPC Joint Distribution here too. We will keep with the theme that this might represent a Expected Loss Cost $E_{loss}$\n",
        "\n",
        "NOTE:\n",
        "\n",
        "+ Within each marginal, the samples for the posterior parameters of a submodel \n",
        "  are coherent across the joint posterior parameter space\n",
        "+ This means for example, that within parameters `yhat0` etc, each of \n",
        "  samples `0, 1, 2, 3 ... j` gives us the full state of the model at that point \n",
        "  in the Markov chain\n",
        "+ So, we use all parameter values at each sample `0, 1, 2, 3 ... j`, to get \n",
        "  `j` estimates of the posterior parameter values, and thus the predictions\n",
        "+ We usually set `j = 2000`, so we have $2000$ predictions for each observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yhat = az.extract(idata_holdout, group=GROUP, var_names=mdl.rvs_ppc).values\n",
        "yhat_eloss = np.product(yhat, axis=1)\n",
        "yhat_eloss.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2.1 Plot holdout Full Set Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_yhat_eloss = pd.DataFrame(yhat_eloss, index=dfx_m0_holdout.index)\n",
        "dfm_yhat_eloss = df_yhat_eloss.reset_index().melt(\n",
        "                        id_vars='index', value_name='yhat', var_name='sample')\n",
        "eda.display_ht(df_yhat_eloss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = eda.plot_estimate(dfm_yhat_eloss, len(df_yhat_eloss), yhat='yhat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = eda.plot_estimate(dfm_yhat_eloss, len(df_yhat_eloss), yhat='yhat', kind='exceedance')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Quite a long tail, high mean, doesn't seem unreasonable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2.2 Plot holdout Individual Observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mn_pt_kws=dict(markerfacecolor='w', markeredgecolor='#333333', marker='d', markersize=8)\n",
        "box_kws=dict(kind='box', sym='', orient='h', showmeans=True, whis=(3, 97), meanprops=mn_pt_kws)\n",
        "nobs = len(df_yhat_eloss)\n",
        "gd = sns.catplot(x='yhat', y='index', data=dfm_yhat_eloss, **box_kws, height=4, aspect=2)\n",
        "_ = gd.fig.suptitle(f'Individual Distribution of yhat Estimate for {nobs} Observations')\n",
        "_ = gd.fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.2.3 Mean Joint Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rv = 'yhat'\n",
        "cols = mdl.coords[f'{rv}_nm']\n",
        "x = az.extract(idata_holdout, group=GROUP, var_names=rv).values\n",
        "dfp_y = pd.DataFrame(np.nanmean(x, axis=2), columns=cols)\n",
        "f = eda.plot_joint_numeric(data=dfp_y, ft0=cols[0], ft1=cols[1], kind='kde+scatter', colori=2, \n",
        "            subtitle='holdout Out-of-Sample Posterior Predictive Marginals (mean)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Quite broad variance\n",
        "+ But marginals and joint look reasonably close to holdout actual values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.2.4 Quantile Joint Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "qs = [0.03, 0.25, 0.5, 0.75, 0.97]\n",
        "dfp_q = pd.DataFrame(np.quantile(x, qs, axis=2).reshape(len(qs)*mdl.n, 2), columns=cols)\n",
        "dfp_q['q'] = np.repeat([f'{q}'  for q in qs], mdl.n)\n",
        "f = eda.plot_joint_numeric(data=dfp_q, ft0=cols[0], ft1=cols[1], hue='q', kind='kde',\n",
        "            legendpos='lower right',\n",
        "            subtitle='holdout Out-of-Sample Posterior Predictive Marginals (quantiles)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe**\n",
        "\n",
        "+ Very interesting! The PPC quantile range looks reasonable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**In the real world, we have to stop here, because in a holdout scenario we dont have `y`**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Evaluate Predictions (Holdout Set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**IMPORTANT NOTE** \n",
        "\n",
        "Strictly speaking, in a **holdout** dataset / scenario we dont have `y`, but in\n",
        "this worked example Notebook we do have `y`, so we can treat this more like a \n",
        "**Holdout** dataset / scenario, and add several evaluations including:\n",
        "\n",
        "+ Plot Summarised Predictions with overplotted Actual\n",
        "+ Plot PPC ECDF\n",
        "+ Plot Coverage / Calibration\n",
        "+ Plot RMSE and R^2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.1 Evaluate holdout Joint Distribution ($E_{loss}$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1.1 Plot Summarised Predictions with overplotted Actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_m0 = dfx_m0_holdout['m0'].values\n",
        "y_m1 = dfx_m1_holdout['m1'].values\n",
        "y_eloss = y_m0 * y_m1\n",
        "df_y_eloss = pd.DataFrame({'y': y_eloss}, index=dfx_m0_holdout.index).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f = eda.plot_estimate(dfm_yhat_eloss, len(df_yhat_eloss), yhat='yhat', \n",
        "                    arroverplot=df_y_eloss['y'], txtadd='with overplotted bootstrapped Actual')\n",
        "figio.write(f, fn=f'100_6.1.1_holdout_prediction_{mdl.name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Now we can see the prediction from this naive model is much too high and the \n",
        "  variance is too large\n",
        "+ The overplotted actual sample mean is 9.3, and the estimated mean is 16.2,\n",
        "  a $16.2/9.3 \\sim +74\\%$ overestimate!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1.2 Plot PPC EDCF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hacky correct for sample_posterior_predictive not creating observed data \n",
        "# (because model observed_RVs is empty)\n",
        "if 'observed_data' not in idata_holdout.groups():\n",
        "    idata_holdout.add_groups(observed_data=deepcopy(mdl.idata.observed_data))\n",
        "\n",
        "idata_holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_ = mt.plot_ppc(mdl, idata=idata_holdout, group='posterior', insamp=False,\n",
        "                data_pairs={'yhat': 'yhat'}, flatten=['oid'], observed_rug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Bulk: reasonably good fits, but high variance\n",
        "+ Tails: reasonable fit, rather heavier than observed, esp for `yhat1`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1.3 Plot Coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_cov_eloss = mt.calc_ppc_coverage(y_eloss, yhat_eloss.T)\n",
        "f = eda.plot_coverage(df_cov_eloss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Reasonably well-calibrated\n",
        "+ AUC: quite large"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1.4: Plot RMSE and R^2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rmse, rmse_pct = mt.calc_rmse(y_eloss, yhat_eloss.T)\n",
        "f = eda.plot_rmse_range(rmse, rmse_pct, yhat_name='yhat_eloss')\n",
        "\n",
        "r2 = mt.calc_bayesian_r2(y_eloss, yhat_eloss)\n",
        "f = eda.plot_float_dist(r2, ['r2'], log=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ RMSE quite high variance\n",
        "+ R^2 mean seems reasonable, but has high variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.2 Evaluate Marginal Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**IMPORTANT NOTE** \n",
        "\n",
        "Strictly speaking, in a **holdout** dataset / scenario we dont have `y`, but in\n",
        "this worked example Notebook we do have `y`, so we can treat this more like a \n",
        "**Holdout** dataset / scenario, and add several evaluations including:\n",
        "\n",
        "+ Plot Coverage\n",
        "+ Plot RMSE and R^2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2.1 Margin M0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6.2.1.1 Coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfcov_m0 = mt.calc_ppc_coverage(y_m0, yhat[:, 0].T)\n",
        "f = eda.plot_coverage(dfcov_m0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Looks pretty well-calibrated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6.2.1.2: RMSE and R^2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rmse, rmse_pct = mt.calc_rmse(y_m0, yhat[:, 0].T)\n",
        "f = eda.plot_rmse_range(rmse, rmse_pct, yhat_name='m0')\n",
        "\n",
        "r2 = mt.calc_bayesian_r2(y_m0, yhat[:, 0])\n",
        "f = eda.plot_float_dist(r2, ['r2'], log=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ RMSE quite high variance\n",
        "+ R^2 mean seems reasonable, but has high variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2.2 Margin M1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6.2.2.1 Coverage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfcov_m1 = mt.calc_ppc_coverage(y_m1, yhat[:, 1].T)\n",
        "f = eda.plot_coverage(dfcov_m1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ Also reasonably well-calibrated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6.2.2.2: RMSE and R^2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rmse, rmse_pct = mt.calc_rmse(y_m1, yhat[:, 1].T)\n",
        "f = eda.plot_rmse_range(rmse, rmse_pct, yhat_name='m1')\n",
        "\n",
        "r2 = mt.calc_bayesian_r2(y_m1, yhat[:, 1])\n",
        "f = eda.plot_float_dist(r2, ['r2'], log=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Observe:**\n",
        "\n",
        "+ RMSE quite high variance\n",
        "+ R^2 mean seems reasonable, but has high variance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext watermark\n",
        "%watermark -a \"jonathan.sedar@oreum.io\" -udtmv -iv -p pymc,pytensor"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "**Oreum O\u00dc &copy; 2024**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "oreum_copula",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
